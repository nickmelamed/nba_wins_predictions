{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffe4b549-14ed-40a1-bdf8-fafcee51a568",
   "metadata": {},
   "source": [
    "# NBA Wins Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d095fc2-bb00-405e-a353-2356be82dd5d",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd5cbb0-636d-486e-a276-bd5880f79c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pymc3 as pm\n",
    "import theano.tensor as tt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "np.random.seed(102) # picking a random seed for model simulations\n",
    "pd.options.mode.chained_assignment = None "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbd5006-6fbe-4d38-940c-f5d830ecfb3c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2985ed-c85f-4461-997b-01d7df0d0794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RANK</th>\n",
       "      <th>TEAM</th>\n",
       "      <th>CONF</th>\n",
       "      <th>DIVISION</th>\n",
       "      <th>GP</th>\n",
       "      <th>PPG</th>\n",
       "      <th>oPPG</th>\n",
       "      <th>pDIFF</th>\n",
       "      <th>PACE</th>\n",
       "      <th>oEFF</th>\n",
       "      <th>...</th>\n",
       "      <th>SAR</th>\n",
       "      <th>CONS</th>\n",
       "      <th>A4F</th>\n",
       "      <th>W</th>\n",
       "      <th>L</th>\n",
       "      <th>WIN%</th>\n",
       "      <th>eWIN%</th>\n",
       "      <th>pWIN%</th>\n",
       "      <th>ACH</th>\n",
       "      <th>STRK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Milwaukee</td>\n",
       "      <td>East</td>\n",
       "      <td>Central</td>\n",
       "      <td>82</td>\n",
       "      <td>116.9</td>\n",
       "      <td>113.3</td>\n",
       "      <td>3.6</td>\n",
       "      <td>100.5</td>\n",
       "      <td>115.5</td>\n",
       "      <td>...</td>\n",
       "      <td>3.16</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.086</td>\n",
       "      <td>58</td>\n",
       "      <td>24</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.619</td>\n",
       "      <td>0.112</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Boston</td>\n",
       "      <td>East</td>\n",
       "      <td>Atlantic</td>\n",
       "      <td>82</td>\n",
       "      <td>117.9</td>\n",
       "      <td>111.4</td>\n",
       "      <td>6.5</td>\n",
       "      <td>98.4</td>\n",
       "      <td>118.1</td>\n",
       "      <td>...</td>\n",
       "      <td>5.76</td>\n",
       "      <td>14.3</td>\n",
       "      <td>0.063</td>\n",
       "      <td>57</td>\n",
       "      <td>25</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.677</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.018</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>East</td>\n",
       "      <td>Atlantic</td>\n",
       "      <td>82</td>\n",
       "      <td>115.2</td>\n",
       "      <td>110.9</td>\n",
       "      <td>4.3</td>\n",
       "      <td>96.8</td>\n",
       "      <td>117.8</td>\n",
       "      <td>...</td>\n",
       "      <td>4.51</td>\n",
       "      <td>13.3</td>\n",
       "      <td>0.021</td>\n",
       "      <td>54</td>\n",
       "      <td>28</td>\n",
       "      <td>0.659</td>\n",
       "      <td>0.629</td>\n",
       "      <td>0.642</td>\n",
       "      <td>0.030</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Denver</td>\n",
       "      <td>West</td>\n",
       "      <td>Northwest</td>\n",
       "      <td>82</td>\n",
       "      <td>115.8</td>\n",
       "      <td>112.5</td>\n",
       "      <td>3.3</td>\n",
       "      <td>98.1</td>\n",
       "      <td>117.6</td>\n",
       "      <td>...</td>\n",
       "      <td>2.84</td>\n",
       "      <td>14.3</td>\n",
       "      <td>0.058</td>\n",
       "      <td>53</td>\n",
       "      <td>29</td>\n",
       "      <td>0.646</td>\n",
       "      <td>0.594</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.052</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>East</td>\n",
       "      <td>Central</td>\n",
       "      <td>82</td>\n",
       "      <td>112.3</td>\n",
       "      <td>106.9</td>\n",
       "      <td>5.4</td>\n",
       "      <td>95.6</td>\n",
       "      <td>116.2</td>\n",
       "      <td>...</td>\n",
       "      <td>4.57</td>\n",
       "      <td>12.9</td>\n",
       "      <td>0.004</td>\n",
       "      <td>51</td>\n",
       "      <td>31</td>\n",
       "      <td>0.622</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.678</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Memphis</td>\n",
       "      <td>West</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>82</td>\n",
       "      <td>116.9</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>101.0</td>\n",
       "      <td>115.1</td>\n",
       "      <td>...</td>\n",
       "      <td>3.31</td>\n",
       "      <td>14.7</td>\n",
       "      <td>0.007</td>\n",
       "      <td>51</td>\n",
       "      <td>31</td>\n",
       "      <td>0.622</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.628</td>\n",
       "      <td>0.020</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Sacramento</td>\n",
       "      <td>West</td>\n",
       "      <td>Pacific</td>\n",
       "      <td>82</td>\n",
       "      <td>120.8</td>\n",
       "      <td>118.1</td>\n",
       "      <td>2.7</td>\n",
       "      <td>100.3</td>\n",
       "      <td>119.5</td>\n",
       "      <td>...</td>\n",
       "      <td>2.11</td>\n",
       "      <td>13.5</td>\n",
       "      <td>0.006</td>\n",
       "      <td>48</td>\n",
       "      <td>34</td>\n",
       "      <td>0.585</td>\n",
       "      <td>0.577</td>\n",
       "      <td>0.589</td>\n",
       "      <td>0.008</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>New York</td>\n",
       "      <td>East</td>\n",
       "      <td>Atlantic</td>\n",
       "      <td>82</td>\n",
       "      <td>116.0</td>\n",
       "      <td>113.1</td>\n",
       "      <td>2.9</td>\n",
       "      <td>97.1</td>\n",
       "      <td>117.8</td>\n",
       "      <td>...</td>\n",
       "      <td>2.88</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.021</td>\n",
       "      <td>47</td>\n",
       "      <td>35</td>\n",
       "      <td>0.573</td>\n",
       "      <td>0.589</td>\n",
       "      <td>0.595</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>East</td>\n",
       "      <td>Atlantic</td>\n",
       "      <td>82</td>\n",
       "      <td>113.4</td>\n",
       "      <td>112.5</td>\n",
       "      <td>0.9</td>\n",
       "      <td>98.3</td>\n",
       "      <td>115.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>15.6</td>\n",
       "      <td>0.036</td>\n",
       "      <td>45</td>\n",
       "      <td>37</td>\n",
       "      <td>0.549</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.028</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>West</td>\n",
       "      <td>Pacific</td>\n",
       "      <td>82</td>\n",
       "      <td>113.6</td>\n",
       "      <td>111.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>98.2</td>\n",
       "      <td>115.2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.44</td>\n",
       "      <td>15.2</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>45</td>\n",
       "      <td>37</td>\n",
       "      <td>0.549</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.566</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Miami</td>\n",
       "      <td>East</td>\n",
       "      <td>Southeast</td>\n",
       "      <td>82</td>\n",
       "      <td>109.5</td>\n",
       "      <td>109.8</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>96.1</td>\n",
       "      <td>113.2</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.37</td>\n",
       "      <td>11.8</td>\n",
       "      <td>-0.070</td>\n",
       "      <td>44</td>\n",
       "      <td>38</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.047</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Golden State</td>\n",
       "      <td>West</td>\n",
       "      <td>Pacific</td>\n",
       "      <td>82</td>\n",
       "      <td>118.9</td>\n",
       "      <td>117.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>101.7</td>\n",
       "      <td>116.4</td>\n",
       "      <td>...</td>\n",
       "      <td>2.07</td>\n",
       "      <td>15.4</td>\n",
       "      <td>0.067</td>\n",
       "      <td>44</td>\n",
       "      <td>38</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.544</td>\n",
       "      <td>0.559</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>LA Clippers</td>\n",
       "      <td>West</td>\n",
       "      <td>Pacific</td>\n",
       "      <td>82</td>\n",
       "      <td>113.6</td>\n",
       "      <td>113.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>97.9</td>\n",
       "      <td>115.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.61</td>\n",
       "      <td>13.5</td>\n",
       "      <td>0.028</td>\n",
       "      <td>44</td>\n",
       "      <td>38</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.515</td>\n",
       "      <td>0.516</td>\n",
       "      <td>0.022</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>LA Lakers</td>\n",
       "      <td>West</td>\n",
       "      <td>Pacific</td>\n",
       "      <td>82</td>\n",
       "      <td>117.2</td>\n",
       "      <td>116.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>101.3</td>\n",
       "      <td>114.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.83</td>\n",
       "      <td>11.3</td>\n",
       "      <td>0.024</td>\n",
       "      <td>43</td>\n",
       "      <td>39</td>\n",
       "      <td>0.524</td>\n",
       "      <td>0.518</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.006</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>West</td>\n",
       "      <td>Northwest</td>\n",
       "      <td>82</td>\n",
       "      <td>115.8</td>\n",
       "      <td>115.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>113.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.32</td>\n",
       "      <td>11.6</td>\n",
       "      <td>0.020</td>\n",
       "      <td>42</td>\n",
       "      <td>40</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.012</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>New Orleans</td>\n",
       "      <td>West</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>82</td>\n",
       "      <td>114.4</td>\n",
       "      <td>112.5</td>\n",
       "      <td>1.9</td>\n",
       "      <td>99.0</td>\n",
       "      <td>114.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.77</td>\n",
       "      <td>14.7</td>\n",
       "      <td>0.001</td>\n",
       "      <td>42</td>\n",
       "      <td>40</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.551</td>\n",
       "      <td>0.563</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>East</td>\n",
       "      <td>Southeast</td>\n",
       "      <td>82</td>\n",
       "      <td>118.4</td>\n",
       "      <td>118.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>100.7</td>\n",
       "      <td>116.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.92</td>\n",
       "      <td>12.9</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.509</td>\n",
       "      <td>0.510</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>East</td>\n",
       "      <td>Atlantic</td>\n",
       "      <td>82</td>\n",
       "      <td>112.9</td>\n",
       "      <td>111.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>97.1</td>\n",
       "      <td>115.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.18</td>\n",
       "      <td>12.5</td>\n",
       "      <td>-0.119</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.548</td>\n",
       "      <td>0.549</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>East</td>\n",
       "      <td>Central</td>\n",
       "      <td>82</td>\n",
       "      <td>113.1</td>\n",
       "      <td>111.8</td>\n",
       "      <td>1.3</td>\n",
       "      <td>98.5</td>\n",
       "      <td>113.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.41</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>40</td>\n",
       "      <td>42</td>\n",
       "      <td>0.488</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.543</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Oklahoma City</td>\n",
       "      <td>West</td>\n",
       "      <td>Northwest</td>\n",
       "      <td>82</td>\n",
       "      <td>117.5</td>\n",
       "      <td>116.4</td>\n",
       "      <td>1.1</td>\n",
       "      <td>101.1</td>\n",
       "      <td>115.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.80</td>\n",
       "      <td>12.7</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>40</td>\n",
       "      <td>42</td>\n",
       "      <td>0.488</td>\n",
       "      <td>0.531</td>\n",
       "      <td>0.536</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>West</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>82</td>\n",
       "      <td>114.2</td>\n",
       "      <td>114.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>96.5</td>\n",
       "      <td>116.9</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>12.3</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>38</td>\n",
       "      <td>44</td>\n",
       "      <td>0.463</td>\n",
       "      <td>0.503</td>\n",
       "      <td>0.503</td>\n",
       "      <td>-0.040</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Utah</td>\n",
       "      <td>West</td>\n",
       "      <td>Northwest</td>\n",
       "      <td>82</td>\n",
       "      <td>117.1</td>\n",
       "      <td>118.1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>100.4</td>\n",
       "      <td>115.8</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.16</td>\n",
       "      <td>11.4</td>\n",
       "      <td>0.043</td>\n",
       "      <td>37</td>\n",
       "      <td>45</td>\n",
       "      <td>0.451</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.467</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Indiana</td>\n",
       "      <td>East</td>\n",
       "      <td>Central</td>\n",
       "      <td>82</td>\n",
       "      <td>116.3</td>\n",
       "      <td>119.5</td>\n",
       "      <td>-3.2</td>\n",
       "      <td>100.9</td>\n",
       "      <td>114.8</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.99</td>\n",
       "      <td>10.8</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>35</td>\n",
       "      <td>47</td>\n",
       "      <td>0.427</td>\n",
       "      <td>0.387</td>\n",
       "      <td>0.395</td>\n",
       "      <td>0.040</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Washington</td>\n",
       "      <td>East</td>\n",
       "      <td>Southeast</td>\n",
       "      <td>82</td>\n",
       "      <td>113.2</td>\n",
       "      <td>114.4</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>98.5</td>\n",
       "      <td>114.5</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>13.2</td>\n",
       "      <td>0.032</td>\n",
       "      <td>35</td>\n",
       "      <td>47</td>\n",
       "      <td>0.427</td>\n",
       "      <td>0.464</td>\n",
       "      <td>0.460</td>\n",
       "      <td>-0.037</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Orlando</td>\n",
       "      <td>East</td>\n",
       "      <td>Southeast</td>\n",
       "      <td>82</td>\n",
       "      <td>111.4</td>\n",
       "      <td>114.0</td>\n",
       "      <td>-2.6</td>\n",
       "      <td>99.2</td>\n",
       "      <td>111.7</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.59</td>\n",
       "      <td>12.1</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>34</td>\n",
       "      <td>48</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.414</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Portland</td>\n",
       "      <td>West</td>\n",
       "      <td>Northwest</td>\n",
       "      <td>82</td>\n",
       "      <td>113.4</td>\n",
       "      <td>117.4</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>98.5</td>\n",
       "      <td>114.8</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.01</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>33</td>\n",
       "      <td>49</td>\n",
       "      <td>0.402</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.368</td>\n",
       "      <td>0.010</td>\n",
       "      <td>-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Charlotte</td>\n",
       "      <td>East</td>\n",
       "      <td>Southeast</td>\n",
       "      <td>82</td>\n",
       "      <td>111.0</td>\n",
       "      <td>117.2</td>\n",
       "      <td>-6.2</td>\n",
       "      <td>100.8</td>\n",
       "      <td>109.3</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.99</td>\n",
       "      <td>13.0</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>27</td>\n",
       "      <td>55</td>\n",
       "      <td>0.329</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.009</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Houston</td>\n",
       "      <td>West</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>82</td>\n",
       "      <td>110.7</td>\n",
       "      <td>118.6</td>\n",
       "      <td>-7.9</td>\n",
       "      <td>99.0</td>\n",
       "      <td>111.4</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.24</td>\n",
       "      <td>12.6</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>22</td>\n",
       "      <td>60</td>\n",
       "      <td>0.268</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.003</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>West</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>82</td>\n",
       "      <td>113.0</td>\n",
       "      <td>123.1</td>\n",
       "      <td>-10.1</td>\n",
       "      <td>101.6</td>\n",
       "      <td>110.3</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.27</td>\n",
       "      <td>14.9</td>\n",
       "      <td>-0.059</td>\n",
       "      <td>22</td>\n",
       "      <td>60</td>\n",
       "      <td>0.268</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.012</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Detroit</td>\n",
       "      <td>East</td>\n",
       "      <td>Central</td>\n",
       "      <td>82</td>\n",
       "      <td>110.3</td>\n",
       "      <td>118.5</td>\n",
       "      <td>-8.2</td>\n",
       "      <td>99.0</td>\n",
       "      <td>110.7</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.38</td>\n",
       "      <td>12.3</td>\n",
       "      <td>-0.040</td>\n",
       "      <td>17</td>\n",
       "      <td>65</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.230</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    RANK           TEAM  CONF   DIVISION  GP    PPG   oPPG  pDIFF   PACE  \\\n",
       "0      1      Milwaukee  East    Central  82  116.9  113.3    3.6  100.5   \n",
       "1      2         Boston  East   Atlantic  82  117.9  111.4    6.5   98.4   \n",
       "2      3   Philadelphia  East   Atlantic  82  115.2  110.9    4.3   96.8   \n",
       "3      4         Denver  West  Northwest  82  115.8  112.5    3.3   98.1   \n",
       "4      5      Cleveland  East    Central  82  112.3  106.9    5.4   95.6   \n",
       "5      6        Memphis  West  Southwest  82  116.9  113.0    3.9  101.0   \n",
       "6      7     Sacramento  West    Pacific  82  120.8  118.1    2.7  100.3   \n",
       "7      8       New York  East   Atlantic  82  116.0  113.1    2.9   97.1   \n",
       "8      9       Brooklyn  East   Atlantic  82  113.4  112.5    0.9   98.3   \n",
       "9     10        Phoenix  West    Pacific  82  113.6  111.6    2.0   98.2   \n",
       "10    11          Miami  East  Southeast  82  109.5  109.8   -0.3   96.1   \n",
       "11    12   Golden State  West    Pacific  82  118.9  117.1    1.8  101.7   \n",
       "12    13    LA Clippers  West    Pacific  82  113.6  113.1    0.5   97.9   \n",
       "13    14      LA Lakers  West    Pacific  82  117.2  116.6    0.6  101.3   \n",
       "14    15      Minnesota  West  Northwest  82  115.8  115.8    0.0  101.0   \n",
       "15    16    New Orleans  West  Southwest  82  114.4  112.5    1.9   99.0   \n",
       "16    17        Atlanta  East  Southeast  82  118.4  118.1    0.3  100.7   \n",
       "17    18        Toronto  East   Atlantic  82  112.9  111.4    1.5   97.1   \n",
       "18    19        Chicago  East    Central  82  113.1  111.8    1.3   98.5   \n",
       "19    20  Oklahoma City  West  Northwest  82  117.5  116.4    1.1  101.1   \n",
       "20    21         Dallas  West  Southwest  82  114.2  114.1    0.1   96.5   \n",
       "21    22           Utah  West  Northwest  82  117.1  118.1   -1.0  100.4   \n",
       "22    23        Indiana  East    Central  82  116.3  119.5   -3.2  100.9   \n",
       "23    24     Washington  East  Southeast  82  113.2  114.4   -1.2   98.5   \n",
       "24    25        Orlando  East  Southeast  82  111.4  114.0   -2.6   99.2   \n",
       "25    26       Portland  West  Northwest  82  113.4  117.4   -4.0   98.5   \n",
       "26    27      Charlotte  East  Southeast  82  111.0  117.2   -6.2  100.8   \n",
       "27    28        Houston  West  Southwest  82  110.7  118.6   -7.9   99.0   \n",
       "28    29    San Antonio  West  Southwest  82  113.0  123.1  -10.1  101.6   \n",
       "29    30        Detroit  East    Central  82  110.3  118.5   -8.2   99.0   \n",
       "\n",
       "     oEFF  ...   SAR  CONS    A4F   W   L   WIN%  eWIN%  pWIN%    ACH  STRK  \n",
       "0   115.5  ...  3.16  15.0  0.086  58  24  0.707  0.595  0.619  0.112    -2  \n",
       "1   118.1  ...  5.76  14.3  0.063  57  25  0.695  0.677  0.714  0.018     3  \n",
       "2   117.8  ...  4.51  13.3  0.021  54  28  0.659  0.629  0.642  0.030     2  \n",
       "3   117.6  ...  2.84  14.3  0.058  53  29  0.646  0.594  0.609  0.052     1  \n",
       "4   116.2  ...  4.57  12.9  0.004  51  31  0.622  0.667  0.678 -0.045    -1  \n",
       "5   115.1  ...  3.31  14.7  0.007  51  31  0.622  0.602  0.628  0.020    -1  \n",
       "6   119.5  ...  2.11  13.5  0.006  48  34  0.585  0.577  0.589  0.008    -3  \n",
       "7   117.8  ...  2.88  13.0  0.021  47  35  0.573  0.589  0.595 -0.016    -2  \n",
       "8   115.0  ...  0.75  15.6  0.036  45  37  0.549  0.521  0.530  0.028    -1  \n",
       "9   115.2  ...  2.44  15.2 -0.001  45  37  0.549  0.555  0.566 -0.006    -2  \n",
       "10  113.2  ... -0.37  11.8 -0.070  44  38  0.537  0.490  0.490  0.047     1  \n",
       "11  116.4  ...  2.07  15.4  0.067  44  38  0.537  0.544  0.559 -0.007     3  \n",
       "12  115.1  ...  0.61  13.5  0.028  44  38  0.537  0.515  0.516  0.022     3  \n",
       "13  114.5  ...  0.83  11.3  0.024  43  39  0.524  0.518  0.520  0.006     2  \n",
       "14  113.8  ...  0.32  11.6  0.020  42  40  0.512  0.500  0.500  0.012     3  \n",
       "15  114.5  ...  1.77  14.7  0.001  42  40  0.512  0.551  0.563 -0.039    -1  \n",
       "16  116.7  ...  0.92  12.9 -0.026  41  41  0.500  0.509  0.510 -0.009    -2  \n",
       "17  115.5  ...  1.18  12.5 -0.119  41  41  0.500  0.548  0.549 -0.048     1  \n",
       "18  113.5  ...  1.41  15.0 -0.013  40  42  0.488  0.534  0.543 -0.046     2  \n",
       "19  115.4  ...  0.80  12.7 -0.068  40  42  0.488  0.531  0.536 -0.043     2  \n",
       "20  116.9  ... -0.25  12.3 -0.002  38  44  0.463  0.503  0.503 -0.040    -2  \n",
       "21  115.8  ... -1.16  11.4  0.043  37  45  0.451  0.465  0.467 -0.014    -1  \n",
       "22  114.8  ... -2.99  10.8 -0.027  35  47  0.427  0.387  0.395  0.040     1  \n",
       "23  114.5  ... -1.00  13.2  0.032  35  47  0.427  0.464  0.460 -0.037    -1  \n",
       "24  111.7  ... -1.59  12.1 -0.015  34  48  0.415  0.415  0.414  0.000    -4  \n",
       "25  114.8  ... -4.01  15.0 -0.015  33  49  0.402  0.392  0.368  0.010    -4  \n",
       "26  109.3  ... -4.99  13.0 -0.044  27  55  0.329  0.320  0.296  0.009     1  \n",
       "27  111.4  ... -7.24  12.6 -0.026  22  60  0.268  0.265  0.240  0.003     3  \n",
       "28  110.3  ... -9.27  14.9 -0.059  22  60  0.268  0.256  0.167  0.012     1  \n",
       "29  110.7  ... -7.38  12.3 -0.040  17  65  0.207  0.250  0.230 -0.043    -1  \n",
       "\n",
       "[30 rows x 24 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team_metrics = pd.read_csv(\"2023_team_metrics\")\n",
    "nba_2023 = pd.read_csv('nba_2023_season.csv')\n",
    "team_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f75d4121",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_player = \"NBA Stats 202223 All Stats  NBA Player Props Tool.csv\"\n",
    "nba_data = pd.read_csv(file_path_player)\n",
    "file_path_team = \"2023_team_metrics\"\n",
    "team_data = pd.read_csv(file_path_team)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a550a8d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RANK</th>\n",
       "      <th>NAME</th>\n",
       "      <th>TEAM</th>\n",
       "      <th>POS</th>\n",
       "      <th>AGE</th>\n",
       "      <th>GP</th>\n",
       "      <th>MPG</th>\n",
       "      <th>USG%</th>\n",
       "      <th>TO%</th>\n",
       "      <th>FTA</th>\n",
       "      <th>...</th>\n",
       "      <th>APG</th>\n",
       "      <th>SPG</th>\n",
       "      <th>BPG</th>\n",
       "      <th>TPG</th>\n",
       "      <th>P+R</th>\n",
       "      <th>P+A</th>\n",
       "      <th>P+R+A</th>\n",
       "      <th>VI</th>\n",
       "      <th>ORtg</th>\n",
       "      <th>DRtg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Joel Embiid</td>\n",
       "      <td>Phi</td>\n",
       "      <td>C-F</td>\n",
       "      <td>29.1</td>\n",
       "      <td>66</td>\n",
       "      <td>34.6</td>\n",
       "      <td>37.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>771</td>\n",
       "      <td>...</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>3.4</td>\n",
       "      <td>43.2</td>\n",
       "      <td>37.2</td>\n",
       "      <td>47.4</td>\n",
       "      <td>13.0</td>\n",
       "      <td>124.4</td>\n",
       "      <td>104.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   RANK         NAME TEAM  POS   AGE  GP   MPG  USG%   TO%  FTA  ...  APG  \\\n",
       "0     1  Joel Embiid  Phi  C-F  29.1  66  34.6  37.0  14.5  771  ...  4.2   \n",
       "\n",
       "   SPG  BPG  TPG   P+R   P+A  P+R+A    VI   ORtg   DRtg  \n",
       "0  1.0  1.7  3.4  43.2  37.2   47.4  13.0  124.4  104.1  \n",
       "\n",
       "[1 rows x 29 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nba_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6a9d9497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['RANK', 'NAME', 'TEAM', 'POS', 'AGE', 'GP', 'MPG', 'USG%', 'TO%', 'FTA',\n",
       "       'FT%', '2PA', '2P%', '3PA', '3P%', 'eFG%', 'TS%', 'PPG', 'RPG', 'APG',\n",
       "       'SPG', 'BPG', 'TPG', 'P+R', 'P+A', 'P+R+A', 'VI', 'ORtg', 'DRtg'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nba_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fa770313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RANK</th>\n",
       "      <th>TEAM</th>\n",
       "      <th>CONF</th>\n",
       "      <th>DIVISION</th>\n",
       "      <th>GP</th>\n",
       "      <th>PPG</th>\n",
       "      <th>oPPG</th>\n",
       "      <th>pDIFF</th>\n",
       "      <th>PACE</th>\n",
       "      <th>oEFF</th>\n",
       "      <th>...</th>\n",
       "      <th>SAR</th>\n",
       "      <th>CONS</th>\n",
       "      <th>A4F</th>\n",
       "      <th>W</th>\n",
       "      <th>L</th>\n",
       "      <th>WIN%</th>\n",
       "      <th>eWIN%</th>\n",
       "      <th>pWIN%</th>\n",
       "      <th>ACH</th>\n",
       "      <th>STRK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Milwaukee</td>\n",
       "      <td>East</td>\n",
       "      <td>Central</td>\n",
       "      <td>82</td>\n",
       "      <td>116.9</td>\n",
       "      <td>113.3</td>\n",
       "      <td>3.6</td>\n",
       "      <td>100.5</td>\n",
       "      <td>115.5</td>\n",
       "      <td>...</td>\n",
       "      <td>3.16</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.086</td>\n",
       "      <td>58</td>\n",
       "      <td>24</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.619</td>\n",
       "      <td>0.112</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Boston</td>\n",
       "      <td>East</td>\n",
       "      <td>Atlantic</td>\n",
       "      <td>82</td>\n",
       "      <td>117.9</td>\n",
       "      <td>111.4</td>\n",
       "      <td>6.5</td>\n",
       "      <td>98.4</td>\n",
       "      <td>118.1</td>\n",
       "      <td>...</td>\n",
       "      <td>5.76</td>\n",
       "      <td>14.3</td>\n",
       "      <td>0.063</td>\n",
       "      <td>57</td>\n",
       "      <td>25</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.677</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.018</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   RANK       TEAM  CONF  DIVISION  GP    PPG   oPPG  pDIFF   PACE   oEFF  \\\n",
       "0     1  Milwaukee  East   Central  82  116.9  113.3    3.6  100.5  115.5   \n",
       "1     2     Boston  East  Atlantic  82  117.9  111.4    6.5   98.4  118.1   \n",
       "\n",
       "   ...   SAR  CONS    A4F   W   L   WIN%  eWIN%  pWIN%    ACH  STRK  \n",
       "0  ...  3.16  15.0  0.086  58  24  0.707  0.595  0.619  0.112    -2  \n",
       "1  ...  5.76  14.3  0.063  57  25  0.695  0.677  0.714  0.018     3  \n",
       "\n",
       "[2 rows x 24 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "491853d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['RANK', 'TEAM', 'CONF', 'DIVISION', 'GP', 'PPG', 'oPPG', 'pDIFF',\n",
       "       'PACE', 'oEFF', 'dEFF', 'eDIFF', 'SOS', 'rSOS', 'SAR', 'CONS', 'A4F',\n",
       "       'W', 'L', 'WIN%', 'eWIN%', 'pWIN%', 'ACH', 'STRK'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718326a0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Prediction with GLMs and nonparametric methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33dbac83",
   "metadata": {},
   "source": [
    "In this research, we aim to predict the success of NBA teams based on various team and player statistics. The goal is to understand which statistics are most influential in determining a team's success and to compare the performance of generalized linear models (GLMs) and nonparametric models in making these predictions. \n",
    "\n",
    "To predict team success, we will primarily use the 'WIN%' feature from the team_data dataset as our target variable, which represents the winning percentage of each team. This is a suitable measure of success as it reflects the proportion of games won out of the total games played.\n",
    "\n",
    "For the features, we will consider a combination of team-level and player-level statistics to capture the overall performance of the teams. The following features are chosen based on their potential relevance to the team's success:\n",
    "\n",
    "1. PPG (Points Per Game) - A higher average points scored per game is generally indicative of a strong offensive team.\n",
    "2. oPPG (Opponent Points Per Game) - A lower average points scored by the opponents per game reflects a strong defensive team.\n",
    "3. PACE (Number of possessions per 48 minutes) - The speed at which a team plays can impact their offensive and defensive strategies.\n",
    "4. oEFF (Offensive Efficiency) - A measure of a team's scoring efficiency, which can indicate the quality of their offense.\n",
    "5. dEFF (Defensive Efficiency) - A measure of a team's ability to prevent opponents from scoring, indicating the quality of their defense.\n",
    "6. eDIFF (Efficiency Differential) - The difference between a team's offensive and defensive efficiency, which can provide an overall assessment of the team's performance.\n",
    "7. USG% (Usage Percentage) - Measures the percentage of team plays involving a specific player while they are on the court. This can help identify key players contributing to the team's success.\n",
    "\n",
    "These features were selected because they capture different aspects of a team's performance, such as offense, defense, pace of play, and individual player contributions. By incorporating these features into our models, we can analyze the relationship between various statistics and the overall success of NBA teams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ee8fd46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map abbreviations to full names\n",
    "team_map = {'Phi': 'Philadelphia', 'Dal': 'Dallas', 'Por': 'Portland', 'Okc': 'Oklahoma City',\n",
    "            'Mil': 'Milwaukee', 'Bos': 'Boston', 'Bro': 'Brooklyn', 'Gol': 'Golden State',\n",
    "            'Lal': 'LA Lakers', 'Cle': 'Cleveland', 'Pho': 'Phoenix', 'Mem': 'Memphis',\n",
    "            'Atl': 'Atlanta', 'Nor': 'New Orleans', 'Uta': 'Utah', 'Nyk': 'New York',\n",
    "            'Sac': 'Sacramento', 'Chi': 'Chicago', 'Min': 'Minnesota', 'Den': 'Denver',\n",
    "            'Tor': 'Toronto', 'Lac': 'LA Clippers', 'Cha': 'Charlotte', 'Was': 'Washington',\n",
    "            'Mia': 'Miami', 'Hou': 'Houston', 'San': 'San Antonio', 'Det': 'Detroit', 'Ind': 'Indiana',\n",
    "            'Orl': 'Orlando'}\n",
    "\n",
    "# abbreviations to full names \n",
    "nba_data['TEAM'] = nba_data['TEAM'].map(team_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1d4f52a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = nba_data.merge(team_data, on=\"TEAM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dcdf5224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RANK_x</th>\n",
       "      <th>NAME</th>\n",
       "      <th>TEAM</th>\n",
       "      <th>POS</th>\n",
       "      <th>AGE</th>\n",
       "      <th>GP_x</th>\n",
       "      <th>MPG</th>\n",
       "      <th>USG%</th>\n",
       "      <th>TO%</th>\n",
       "      <th>FTA</th>\n",
       "      <th>...</th>\n",
       "      <th>SAR</th>\n",
       "      <th>CONS</th>\n",
       "      <th>A4F</th>\n",
       "      <th>W</th>\n",
       "      <th>L</th>\n",
       "      <th>WIN%</th>\n",
       "      <th>eWIN%</th>\n",
       "      <th>pWIN%</th>\n",
       "      <th>ACH</th>\n",
       "      <th>STRK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Joel Embiid</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>C-F</td>\n",
       "      <td>29.1</td>\n",
       "      <td>66</td>\n",
       "      <td>34.6</td>\n",
       "      <td>37.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>771</td>\n",
       "      <td>...</td>\n",
       "      <td>4.51</td>\n",
       "      <td>13.3</td>\n",
       "      <td>0.021</td>\n",
       "      <td>54</td>\n",
       "      <td>28</td>\n",
       "      <td>0.659</td>\n",
       "      <td>0.629</td>\n",
       "      <td>0.642</td>\n",
       "      <td>0.03</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   RANK_x         NAME          TEAM  POS   AGE  GP_x   MPG  USG%   TO%  FTA  \\\n",
       "0       1  Joel Embiid  Philadelphia  C-F  29.1    66  34.6  37.0  14.5  771   \n",
       "\n",
       "   ...   SAR  CONS    A4F   W   L   WIN%  eWIN%  pWIN%   ACH  STRK  \n",
       "0  ...  4.51  13.3  0.021  54  28  0.659  0.629  0.642  0.03     2  \n",
       "\n",
       "[1 rows x 52 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "80757e46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['RANK_x', 'NAME', 'TEAM', 'POS', 'AGE', 'GP_x', 'MPG', 'USG%', 'TO%',\n",
       "       'FTA', 'FT%', '2PA', '2P%', '3PA', '3P%', 'eFG%', 'TS%', 'PPG_x', 'RPG',\n",
       "       'APG', 'SPG', 'BPG', 'TPG', 'P+R', 'P+A', 'P+R+A', 'VI', 'ORtg', 'DRtg',\n",
       "       'RANK_y', 'CONF', 'DIVISION', 'GP_y', 'PPG_y', 'oPPG', 'pDIFF', 'PACE',\n",
       "       'oEFF', 'dEFF', 'eDIFF', 'SOS', 'rSOS', 'SAR', 'CONS', 'A4F', 'W', 'L',\n",
       "       'WIN%', 'eWIN%', 'pWIN%', 'ACH', 'STRK'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb94610",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Bayesian Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a258a3c",
   "metadata": {},
   "source": [
    "**Methods**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01394238",
   "metadata": {},
   "source": [
    "For this research question, we will use a Bayesian linear regression model as our Bayesian GLM. We chose this model because it is a flexible and interpretable method for predicting the success of NBA teams based on the selected features. Linear regression models assume a linear relationship between the predictors and the target variable, which can help us understand the individual contributions of each feature to the winning percentage of the teams.\n",
    "We used a Gaussian likelihood. The link function in this case is the identity function. This choice is made based on the assumption that the relationship between the predictor variables and the target variable is linear, and that the distribution of the target variable is approximately Gaussian given the predictor variables.\n",
    "\n",
    "The Bayesian linear regression model assumes the following form:\n",
    "\n",
    "`WIN% = β0 + β1 * PPG + β2 * oPPG + β3 * PACE + β4 * oEFF + β5 * dEFF + β6 * eDIFF + β7 * USG% + ε`\n",
    "\n",
    "where βi represents the coefficients for each feature, and ε is the error term.\n",
    "\n",
    "The Bayesian approach incorporates prior knowledge about the model parameters (coefficients) in the form of prior distributions. We will use weakly informative priors for the coefficients, such as normal distributions with a mean of 0 and a large variance (e.g., 100). The choice of weakly informative priors allows the data to play a more significant role in updating the posterior distribution, while still regularizing the model to some extent, preventing overfitting.\n",
    "\n",
    "Assumptions made by the Bayesian linear regression model include:\n",
    "\n",
    "1. Linearity: The relationship between the predictors and the target variable is assumed to be linear. This may not always hold true in practice, but it serves as a starting point for understanding the relationships between the features and the winning percentage.\n",
    "2. Independence: The observations are assumed to be independent of each other. In the context of the NBA, this might not be completely accurate, as team performance can be influenced by various external factors such as injuries or changes in coaching staff. However, this assumption simplifies the model and allows us to focus on the relationships between the features and the target variable.\n",
    "3. Homoscedasticity: The model assumes that the variance of the error term is constant across all levels of the predictors. This might not always be true in practice, as certain predictors may exhibit different variances at different levels.\n",
    "\n",
    "By using a Bayesian linear regression model, we can estimate the uncertainty in our predictions and gain insights into the relationships between the features and the winning percentage of NBA teams. The choice of weakly informative priors helps balance the influence of the data and the prior information, resulting in a more robust model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "55e60c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relevant columns \n",
    "data = merged_data[['PPG_y', 'oPPG', 'PACE', 'oEFF', 'dEFF', 'eDIFF', 'USG%', 'WIN%']]\n",
    "\n",
    "# Standardize the predictors to have mean 0 and std 1\n",
    "standardized_data = (data - data.mean()) / data.std()\n",
    "\n",
    "# predictors (X) and target variable (y)\n",
    "X = standardized_data.drop('WIN%', axis=1)\n",
    "y = standardized_data['WIN%']\n",
    "\n",
    "# training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4c1954",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_243/482350756.py:15: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(2000, tune=1000, cores=2)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (2 chains in 2 jobs)\n",
      "NUTS: [sigma, betas, beta_0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='5320' class='' max='6000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      88.67% [5320/6000 03:26&lt;00:26 Sampling 2 chains, 1,877 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model specification\n",
    "with pm.Model() as bayesian_model:\n",
    "    # Priors\n",
    "    beta_0 = pm.Normal('beta_0', mu=0, sd=100)\n",
    "    betas = pm.Normal('betas', mu=0, sd=100, shape=X_train.shape[1])\n",
    "\n",
    "    # Linear regression model\n",
    "    mu = beta_0 + tt.dot(X_train, betas)\n",
    "\n",
    "    # Likelihood\n",
    "    sigma = pm.HalfNormal('sigma', sd=100)\n",
    "    y_obs = pm.Normal('y_obs', mu=mu, sd=sigma, observed=y_train)\n",
    "\n",
    "    # Sample from the posterior\n",
    "    trace = pm.sample(2000, tune=1000, cores=2)\n",
    "\n",
    "# summary\n",
    "pm.summary(trace).round(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5001a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model evaluation\n",
    "with bayesian_model:\n",
    "    # Posterior predictive checks (PPC) on test data\n",
    "    ppc = pm.sample_posterior_predictive(trace, var_names=['beta_0', 'betas', 'sigma'], samples=500)\n",
    "    y_pred = ppc['beta_0'].mean(axis=0) + np.dot(X_test, ppc['betas'].mean(axis=0))\n",
    "\n",
    "    # mean squared error (MSE)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    print(f'Mean squared error: {mse:.2f}')\n",
    "\n",
    "    # R-squared score\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(f'R-squared score: {r2:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e00066",
   "metadata": {},
   "source": [
    "**Results and Discussion**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc68dd3b",
   "metadata": {},
   "source": [
    "Based on the mean squared error (MSE) of 0.07 and the R-squared score of 0.92, the Bayesian GLM appears to perform well on the test data. The low MSE suggests that the model's predictions are close to the true values, and the high R-squared score indicates that the model explains a large proportion of the variance in the dependent variable. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0d9f03",
   "metadata": {},
   "source": [
    "Since the model only considers a limited set of features, some that could have a significant impact on team success are excluded, such as team chemistry, coaching, and injuries. Additionally, the model assumes a linear relationship between the features and the target, which may not always be the case. Finally, the model was trained on a single season of data, so its ability to generalize to other seasons is uncertain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fd41b2",
   "metadata": {},
   "source": [
    "The uncertainty in the results is relatively low, which is indicated by the narrow credible intervals (hdi_3% to hdi_97%) for the parameters and the relatively small standard deviations for most of the variables. However, there is a high uncertainty in the estimates for betas[3], betas[4], and betas[5], as indicated by their wide credible intervals and high standard deviations. This high uncertainty may be due to the relatively small dataset size, the noise in the data, or the complexity of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3d711e",
   "metadata": {},
   "source": [
    "Generalizability will be limited since the model is based on data for just one year.\n",
    "\n",
    "Based on the findings, it may be helpful for NBA teams to consider incorporating the features with low uncertainty such as PPG (Points Per Game), oPPG (Opponent Points Per Game), PACE (Number of possessions per 48 minutes), and USG% (Usage Percentage) used in the model when making decisions related to team composition and strategy.\n",
    "\n",
    "We merged two different data sources, the NBA player statistics and team statistics, in order to create a more comprehensive dataset for our analysis. The benefits of this approach are that we are able to capture a wider range of factors that could impact team success. However, the consequences include potential issues with data quality and reliability, as well as potential biases introduced by combining different sources.\n",
    "\n",
    "Limitations in the data include potential measurement errors in the statistics, as well as potential omitted variable biases if important features were not included in the model. Additional data that could be useful for improving the model includes information on team injuries, team chemistry, and coaching strategies.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdc39ad",
   "metadata": {},
   "source": [
    "# Frequentist Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742be33b",
   "metadata": {},
   "source": [
    "**Methods**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e73f21",
   "metadata": {},
   "source": [
    "For the frequentist modeling, we will use a linear regression model to predict the success of NBA teams based on the selected features. This choice is consistent with the Bayesian GLM used earlier, and allows us to compare the performance of both approaches. Linear regression models assume a linear relationship between the predictors and the target variable, which can help us understand the individual contributions of each feature to the winning percentage of the teams."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc9543c",
   "metadata": {},
   "source": [
    "The frequentist linear regression model assumes the following form:\n",
    "\n",
    "WIN% = β0 + β1 * PPG + β2 * oPPG + β3 * PACE + β4 * oEFF + β5 * dEFF + β6 * eDIFF + β7 * USG% + ε\n",
    "\n",
    "where βi represents the coefficients for each feature, and ε is the error term.\n",
    "\n",
    "Assumptions made by the frequentist linear regression model are the same as those made by the Bayesian linear regression model, which include linearity, independence, and homoscedasticity.\n",
    "\n",
    "We will use the same dataset, features, and target variable as the Bayesian GLM, and we will also standardize the predictors to have mean 0 and std 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd9b6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_regression = LinearRegression()\n",
    "\n",
    "linear_regression.fit(X_train, y_train)\n",
    "\n",
    "y_pred_frequentist = linear_regression.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f194777a",
   "metadata": {},
   "source": [
    "Results and Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8151a5",
   "metadata": {},
   "source": [
    "The frequentist linear regression model yielded a mean squared error (MSE) of 0.05 and an R-squared score of 0.94. These results suggest that the model performed well in predicting team success based on the selected features. The low MSE indicates that the model's predictions are close to the true values, while the high R-squared score shows that the model explains a large proportion of the variance in the dependent variable.\n",
    "\n",
    "Unlike the Bayesian GLM, the frequentist model does not provide uncertainty estimates for the predictions. It is important to note that uncertainty estimates can be useful for decision-makers, as they provide an indication of the confidence associated with the model's predictions.\n",
    "\n",
    "For the same reasons as Bayesian, generalizability of the results is limited. This means that its ability to predict team success in other seasons or under different conditions might not be as accurate. To improve generalizability, future studies could consider using data from multiple seasons or incorporating additional features that could impact team success.\n",
    "\n",
    "We used the same merged dataset as in Bayesian which has the same limitations and hence, the same suggestions for improvement.\n",
    "\n",
    "Future studies could build on this work by trying the model across other years, exploring additional features that could impact team success, and using different modeling techniques to compare and contrast the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced1f496",
   "metadata": {},
   "source": [
    "# Comparison of Frequentist and Bayesian"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb97793c",
   "metadata": {},
   "source": [
    "Both the Bayesian and frequentist linear regression models performed well in predicting team success based on the selected features. The Bayesian GLM had a mean squared error (MSE) of 0.07 and an R-squared score of 0.92, while the frequentist model had a slightly better MSE of 0.05 and an R-squared score of 0.94. The low MSE values for both models indicate that their predictions are close to the true values, and the high R-squared scores suggest that the models explain a large proportion of the variance in the dependent variable.\n",
    "\n",
    "One key difference between the Bayesian and frequentist implementations is that the Bayesian GLM provides uncertainty estimates for the predictions, which can be useful for decision-makers as they indicate the level of confidence associated with the model's predictions. The frequentist model does not provide such estimates. This can be considered an advantage of the Bayesian model, especially in situations where understanding the uncertainty associated with predictions is crucial for decision-making.\n",
    "\n",
    "The better performance of the frequentist model might be due to the relatively small dataset size and the noise in the data, which could have resulted in a higher uncertainty in the estimates for some of the features in the Bayesian model. However, the performance difference between the two models is not substantial, and both models seem to fit the data well.\n",
    "\n",
    "Despite the good performance of both models on this dataset, generalizability to future datasets is limited. Both models were trained on a single season of data, and their ability to predict team success in other seasons or under different conditions might not be as accurate. To improve generalizability, future studies could consider using data from multiple seasons, incorporating additional features that could impact team success, and using different modeling techniques to compare and contrast the results.\n",
    "\n",
    "In conclusion, both Bayesian and frequentist linear regression models performed well on this dataset, but their generalizability to future datasets is uncertain. While the frequentist model had slightly better performance metrics, the Bayesian model provided uncertainty estimates, which can be valuable for decision-making. Future studies should aim to improve generalizability by incorporating more data and exploring additional features that could impact team success."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21550fce",
   "metadata": {},
   "source": [
    "# Nonparametric Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfe5542",
   "metadata": {},
   "source": [
    "We are trying to predict the same target variable as above using the same features for ease of comparison between the models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac7500f",
   "metadata": {},
   "source": [
    "# Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0650932c",
   "metadata": {},
   "source": [
    "**Methods**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9321dca",
   "metadata": {},
   "source": [
    "The first parametric model we will be using is Random Forests. We chose to use Random Forests for this problem because it is a powerful and versatile method that can capture complex relationships between features and target variables. Random Forests are an ensemble learning method that constructs multiple decision trees and combines their predictions to improve the overall accuracy and control overfitting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aad82a8",
   "metadata": {},
   "source": [
    "The main assumptions made by Random Forests are:\n",
    "\n",
    "The underlying relationship between features and the target variable can be modeled using decision trees.\n",
    "The ensemble of decision trees can approximate the true relationship better than individual trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f34de17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparation\n",
    "features = ['PPG_x', 'oPPG', 'PACE', 'oEFF', 'dEFF', 'eDIFF', 'USG%']\n",
    "target = 'WIN%'\n",
    "\n",
    "X = merged_data[features]\n",
    "y = merged_data[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Training\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R2 Score:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194d93d1",
   "metadata": {},
   "source": [
    "**Results and Discussion**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7afa982",
   "metadata": {},
   "source": [
    "The results from the Random Forest model show a Mean Squared Error (MSE) of 1.7984396965932088e-31 and an R2 Score of 1.0. These results suggest that the model fits the data perfectly, which is quite surprising. In practice, a perfect fit is very unlikely and may indicate that the model is overfitting the training data, or there might be data leakage.\n",
    "\n",
    "When applying this model to future datasets, it is important to be cautious, as the model may not generalize well to new data. Overfitting can lead to poor performance on unseen data, and the perfect R2 score observed here raises concerns about the model's ability to generalize.\n",
    "\n",
    "The limitations of the model include:\n",
    "\n",
    "1. Overfitting: The model may have learned the noise in the training data, which can lead to poor performance on new data.\n",
    "2. Data leakage: The presence of information in the training set that should not be available during the learning process may have allowed the model to achieve a perfect fit.\n",
    "3. Limited feature set: The model may not capture all relevant features that contribute to a team's success, such as player injuries, coaching strategies, or team chemistry.\n",
    "\n",
    "To improve the model and increase confidence in its applicability to future datasets, the following steps can be taken:\n",
    "\n",
    "1. Investigate and address potential data leakage, ensuring that the training data does not contain information that should not be available during the learning process.\n",
    "2. Regularize the model to reduce overfitting, by tuning hyperparameters like maximum depth, minimum samples per leaf, and the number of trees in the ensemble.\n",
    "3. Cross-validate the model to obtain a more accurate estimate of its performance on unseen data.\n",
    "4. Include additional relevant features, such as player injuries, coaching strategies, and team chemistry, to better capture the factors that contribute to a team's success.\n",
    "5. Collect more data or increase the size of the dataset to reduce the uncertainty in the results.\n",
    "\n",
    "The uncertainty in the results is qualitatively low, as the R2 score is 1.0, indicating a perfect fit. However, this can be deceptive, as the uncertainty may be due to factors like overfitting or data leakage. It is essential to address these issues before trusting the model's predictions for new data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80b0942",
   "metadata": {},
   "source": [
    "# Validation Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0752b610",
   "metadata": {},
   "source": [
    "As a validation dataset, we will use the playoffs data from the same dataset. \n",
    "Using playoff data as a validation dataset can be both a good choice and a not-so-good choice for different reasons:\n",
    "\n",
    "**Good choice:**\n",
    "\n",
    "Temporal Consistency: Since the playoff data is from the same season as the regular season data, the player and team performances are more likely to be consistent, and the models trained on the regular season data can be expected to perform reasonably well on the playoff data.\n",
    "\n",
    "**Not-so-good choice:**\n",
    "\n",
    "Change in Dynamics: The dynamics of playoff games are usually different from those of regular-season games. During the playoffs, teams may change their strategies, and players may perform differently due to the higher stakes and competitive environment. As a result, models trained on regular-season data might not fully capture these differences and may not generalize well to the playoff data. \n",
    "\n",
    "It also allows us to guage how the models will perform on unseen datasets giving an idea of generalizability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cfd9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_player_playoffs = \"Player_Playoffs_2023\"\n",
    "nba_data_playoffs = pd.read_csv(file_path_player_playoffs)\n",
    "file_path_team_Playoffs = \"Team_Playoffs_2023\"\n",
    "team_data_playoffs = pd.read_csv(file_path_team_Playoffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ee2b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_data_playoffs.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9036d0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "team_data_playoffs.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98c7d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map abbreviations to full names\n",
    "team_map_playoffs = {'Phi': 'Philadelphia', 'Dal': 'Dallas', 'Por': 'Portland', 'Okc': 'Oklahoma City',\n",
    "            'Mil': 'Milwaukee', 'Bos': 'Boston', 'Bro': 'Brooklyn', 'Gol': 'Golden State',\n",
    "            'Lal': 'LA Lakers', 'Cle': 'Cleveland', 'Pho': 'Phoenix', 'Mem': 'Memphis',\n",
    "            'Atl': 'Atlanta', 'Nor': 'New Orleans', 'Uta': 'Utah', 'Nyk': 'New York',\n",
    "            'Sac': 'Sacramento', 'Chi': 'Chicago', 'Min': 'Minnesota', 'Den': 'Denver',\n",
    "            'Tor': 'Toronto', 'Lac': 'LA Clippers', 'Cha': 'Charlotte', 'Was': 'Washington',\n",
    "            'Mia': 'Miami', 'Hou': 'Houston', 'San': 'San Antonio', 'Det': 'Detroit', 'Ind': 'Indiana',\n",
    "            'Orl': 'Orlando'}\n",
    "\n",
    "# abbreviations to full names \n",
    "nba_data_playoffs['TEAM'] = nba_data_playoffs['TEAM'].map(team_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2239596a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_data_playoffs.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4259cd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data_playoffs = nba_data_playoffs.merge(team_data_playoffs, on=\"TEAM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749087fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data_playoffs.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e0d4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relevant columns \n",
    "data_playoffs = merged_data_playoffs[['PPG_y', 'oPPG', 'PACE', 'oEFF', 'dEFF', 'eDIFF', 'USG%', 'WIN%']]\n",
    "\n",
    "# Standardize the predictors to have mean 0 and std 1\n",
    "standardized_data_playoffs = (data_playoffs - data_playoffs.mean()) / data_playoffs.std()\n",
    "\n",
    "# predictors (X) and target variable (y)\n",
    "X_playoffs = standardized_data_playoffs.drop('WIN%', axis=1)\n",
    "y_playoffs = standardized_data_playoffs['WIN%']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e801f51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Bayesian Model Evaluation on Validation Dataset\n",
    "with bayesian_model:\n",
    "    ppc_playoffs = pm.sample_posterior_predictive(trace, var_names=['beta_0', 'betas', 'sigma'], samples=500)\n",
    "    y_pred_bayesian_playoffs = ppc_playoffs['beta_0'].mean(axis=0) + np.dot(X_playoffs, ppc_playoffs['betas'].mean(axis=0))\n",
    "\n",
    "    mse_bayesian_playoffs = mean_squared_error(y_playoffs, y_pred_bayesian_playoffs)\n",
    "    print(f'Mean squared error (Bayesian - Validation): {mse_bayesian_playoffs:.2f}')\n",
    "\n",
    "    r2_bayesian_playoffs = r2_score(y_playoffs, y_pred_bayesian_playoffs)\n",
    "    print(f'R-squared score (Bayesian - Validation): {r2_bayesian_playoffs:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a140217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequentist Model Evaluation on Validation Dataset\n",
    "y_pred_frequentist_playoffs = linear_regression.predict(X_playoffs)\n",
    "\n",
    "mse_frequentist_playoffs = mean_squared_error(y_playoffs, y_pred_frequentist_playoffs)\n",
    "print(f'Mean squared error (Frequentist - Validation): {mse_frequentist_playoffs:.2f}')\n",
    "\n",
    "r2_frequentist_playoffs = r2_score(y_playoffs, y_pred_frequentist_playoffs)\n",
    "print(f'R-squared score (Frequentist - Validation): {r2_frequentist_playoffs:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7021072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Model Evaluation on Validation Dataset\n",
    "y_pred_rf_playoffs = rf_model.predict(X_playoffs)\n",
    "\n",
    "mse_rf_playoffs = mean_squared_error(y_playoffs, y_pred_rf_playoffs)\n",
    "print(f'Mean squared error (Random Forest - Validation): {mse_rf_playoffs:.2f}')\n",
    "\n",
    "r2_rf_playoffs = r2_score(y_playoffs, y_pred_rf_playoffs)\n",
    "print(f'R-squared score (Random Forest - Validation): {r2_rf_playoffs:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0681f5e",
   "metadata": {},
   "source": [
    "The results of the model evaluations on the validation dataset are as follows:\n",
    "\n",
    "1. Bayesian Model:\n",
    "- Mean squared error (MSE): 1.21\n",
    "- R-squared score: -0.21\n",
    "\n",
    "2. Frequentist Model (Linear Regression):\n",
    "- Mean squared error (MSE): 598235153369958413366198272.00\n",
    "- R-squared score: -601017642455400001457618944.00\n",
    "\n",
    "3. Random Forest Model:\n",
    "- Mean squared error (MSE): 1.15\n",
    "- R-squared score: -0.16\n",
    "\n",
    "Based on the MSE and R-squared scores, the Random Forest model performed better on the validation dataset. The Bayesian model had a slightly higher MSE and a lower R-squared score, but its performance is closer to the Random Forest model. The Frequentist model had a significantly higher MSE and a much lower R-squared score, indicating that it performed poorly on the validation dataset.\n",
    "\n",
    "Differences between the Bayesian and Frequentist implementations of the GLM can be attributed to their underlying assumptions and methodologies. The Bayesian approach incorporates prior knowledge, which can help improve model performance when the dataset is small or noisy. On the other hand, the Frequentist approach relies solely on the data at hand, which can make it more sensitive to outliers and noise in the data.\n",
    "\n",
    "The limitations of each model are as follows:\n",
    "- Bayesian Model: Computationally expensive, sensitive to the choice of priors, and requires more domain knowledge.\n",
    "- Frequentist Model: Sensitive to outliers and noise, relies solely on the data at hand, and can result in overfitting when there are many features.\n",
    "- Random Forest Model: Can be prone to overfitting when the trees are deep, and may not perform well on data with very different characteristics from the training data.\n",
    "\n",
    "Additional data that would be useful for improving the models include:\n",
    "- More recent data to account for the latest trends and player performance.\n",
    "- Additional features such as player injuries, coaching strategies, and team chemistry.\n",
    "\n",
    "The uncertainty in the results could be attributed to several factors, including noisy data, small dataset size, and variance in the estimation. Although the Random Forest model performed better, the R-squared score of -0.16 indicates that there is room for improvement, and the models may not generalize well to future datasets. As such, it is essential to validate and update the models as new data becomes available, and consider incorporating additional features and other modeling techniques to improve performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6a3a86",
   "metadata": {},
   "source": [
    "# Predicting Playoff Teams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74209111",
   "metadata": {},
   "source": [
    "In this section we will use the original models to predict the top 16 teams that make it to the playoffs based on regular season data and compare it to the actual teams that make it. Making it to the playoffs is an indication of a team's success in the regular season since only 16 out of the 30 teams make it to the playoffs based on their wins and performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f368fa83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bayesian model predictions\n",
    "y_pred_bayesian = ppc['beta_0'].mean(axis=0) + np.dot(X_test, ppc['betas'].mean(axis=0))\n",
    "\n",
    "# Frequentist model predictions\n",
    "y_pred_frequentist = linear_regression.predict(X_test)\n",
    "\n",
    "# Random Forest model predictions\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Combine team names and predictions\n",
    "results = X_test.copy()\n",
    "results['TEAM'] = merged_data['TEAM']\n",
    "results['bayesian_pred'] = y_pred_bayesian\n",
    "results['frequentist_pred'] = y_pred_frequentist\n",
    "results['rf_pred'] = y_pred_rf\n",
    "\n",
    "# Reset the index of `results` to be the same as the index of `X_test`\n",
    "results.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# actual playoff teams\n",
    "actual_playoff_teams = team_data_playoffs['TEAM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb52fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n_unique_teams(y_pred, results, n=16):\n",
    "    # Get the indices sorted by prediction value (descending order)\n",
    "    sorted_indices = np.argsort(y_pred)[::-1]\n",
    "\n",
    "    # Get the top n unique team names\n",
    "    selected_teams = []\n",
    "    for index in sorted_indices:\n",
    "        team = results.loc[index, \"TEAM\"]\n",
    "        if team not in selected_teams:\n",
    "            selected_teams.append(team)\n",
    "            if len(selected_teams) == n:\n",
    "                break\n",
    "\n",
    "    return pd.Series(selected_teams, name=\"TEAM\")\n",
    "\n",
    "\n",
    "# Get the top 16 unique teams for each model\n",
    "top_16_teams_bayesian = get_top_n_unique_teams(y_pred_bayesian, results)\n",
    "top_16_teams_frequentist = get_top_n_unique_teams(y_pred_frequentist, results)\n",
    "top_16_teams_rf = get_top_n_unique_teams(y_pred_rf, results)\n",
    "\n",
    "# results\n",
    "print(\"Top 16 Teams (Bayesian):\")\n",
    "print(top_16_teams_bayesian)\n",
    "print(\"\\nTop 16 Teams (Frequentist):\")\n",
    "print(top_16_teams_frequentist)\n",
    "print(\"\\nTop 16 Teams (Random Forest):\")\n",
    "print(top_16_teams_rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fa330e",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_teams_frequentist = set(top_16_teams_bayesian).intersection(actual_playoff_teams)\n",
    "correct_teams_bayesian = set(top_16_teams_bayesian).intersection(actual_playoff_teams)\n",
    "correct_teams_rf = set(top_16_teams_rf).intersection(actual_playoff_teams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36341d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Correct predictions (Bayesian): {len(correct_teams_bayesian)}')\n",
    "print(f'Correct predictions (Frequentist): {len(correct_teams_frequentist)}')\n",
    "print(f'Correct predictions (Random Forest): {len(correct_teams_rf)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547b5ae9",
   "metadata": {},
   "source": [
    "In this section, we used the original models to predict the top 16 teams most likely to make it to the playoffs. The Bayesian and Frequentist models got 12 teams right, while Random Forest got 15 teams right. This is consistent with our models comparison section where Random Forests outperformed both models on the validation dataset. Additionally it indicates the real world use of our predictions whereby using these features predictions can be made on team success."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ffc406",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330a0c2e",
   "metadata": {},
   "source": [
    "Based on the results, decision-makers in the NBA can use the models to inform their decisions related to team composition and strategy, but they should also consider the limitations and uncertainties associated with the models. The Bayesian model provides uncertainty estimates, which can be useful for decision-making, while the frequentist model has slightly better performance metrics. The Random Forest model performed the best in predicting team success, but the perfect fit may indicate overfitting or data leakage, and further investigation is needed to increase confidence in its applicability to future datasets.\n",
    "\n",
    "A limitation of the models is that they only consider a limited set of features and do not capture factors such as team chemistry, coaching, and injuries. Future work could incorporate additional features and explore different modeling techniques to improve the models' performance and generalizability.\n",
    "\n",
    "The results also show that the models' predictions are consistent with the actual teams that made it to the playoffs, suggesting their real-world applicability. However, decision-makers should still exercise caution when using the models to inform their decisions and consider additional factors that may impact team success.\n",
    "\n",
    "In summary, the models provide a useful tool for predicting team success based on selected features, but decision-makers should consider their limitations and uncertainties. Future work could explore additional features and modeling techniques to improve performance and generalizability.\n",
    "\n",
    "A call to action based on the results is to encourage decision-makers in the NBA to use these models as one of many tools to inform their decisions related to team composition and strategy. The models provide valuable insights into the relationships between features and team success and can help decision-makers make more informed decisions. However, decision-makers should also consider other factors that may impact team success, such as team chemistry, coaching, and injuries, and exercise caution when using the models to inform their decisions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
