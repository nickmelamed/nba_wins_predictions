{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffe4b549-14ed-40a1-bdf8-fafcee51a568",
   "metadata": {},
   "source": [
    "# NBA Wins Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d095fc2-bb00-405e-a353-2356be82dd5d",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2bd5cbb0-636d-486e-a276-bd5880f79c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "#import pymc3 as pm\n",
    "#import theano.tensor as tt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "np.random.seed(102) # picking a random seed for model simulations\n",
    "pd.options.mode.chained_assignment = None "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbd5006-6fbe-4d38-940c-f5d830ecfb3c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Do Advanced Metrics Have Predictive Value for Team Wins?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934d0f5c-80d5-48d5-8e63-f9ccfe1ec510",
   "metadata": {},
   "source": [
    "We will be using a Random Forest to see if a mix of advanced statistics can determine win count and whether or not a team made the playoffs, and a Bayesian model to see if making parametric assumptions about these statistics will make win predictions more difficult."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bd5c80-0376-4040-bb30-9dda20f740cb",
   "metadata": {},
   "source": [
    "### Loading and Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac2985ed-c85f-4461-997b-01d7df0d0794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RANK</th>\n",
       "      <th>TEAM</th>\n",
       "      <th>CONF</th>\n",
       "      <th>DIVISION</th>\n",
       "      <th>GP</th>\n",
       "      <th>PPG</th>\n",
       "      <th>oPPG</th>\n",
       "      <th>pDIFF</th>\n",
       "      <th>PACE</th>\n",
       "      <th>oEFF</th>\n",
       "      <th>...</th>\n",
       "      <th>SAR</th>\n",
       "      <th>CONS</th>\n",
       "      <th>A4F</th>\n",
       "      <th>W</th>\n",
       "      <th>L</th>\n",
       "      <th>WIN%</th>\n",
       "      <th>eWIN%</th>\n",
       "      <th>pWIN%</th>\n",
       "      <th>ACH</th>\n",
       "      <th>STRK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Milwaukee</td>\n",
       "      <td>East</td>\n",
       "      <td>Central</td>\n",
       "      <td>82</td>\n",
       "      <td>116.9</td>\n",
       "      <td>113.3</td>\n",
       "      <td>3.6</td>\n",
       "      <td>100.5</td>\n",
       "      <td>115.5</td>\n",
       "      <td>...</td>\n",
       "      <td>3.16</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.086</td>\n",
       "      <td>58</td>\n",
       "      <td>24</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.619</td>\n",
       "      <td>0.112</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Boston</td>\n",
       "      <td>East</td>\n",
       "      <td>Atlantic</td>\n",
       "      <td>82</td>\n",
       "      <td>117.9</td>\n",
       "      <td>111.4</td>\n",
       "      <td>6.5</td>\n",
       "      <td>98.4</td>\n",
       "      <td>118.1</td>\n",
       "      <td>...</td>\n",
       "      <td>5.76</td>\n",
       "      <td>14.3</td>\n",
       "      <td>0.063</td>\n",
       "      <td>57</td>\n",
       "      <td>25</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.677</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.018</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>East</td>\n",
       "      <td>Atlantic</td>\n",
       "      <td>82</td>\n",
       "      <td>115.2</td>\n",
       "      <td>110.9</td>\n",
       "      <td>4.3</td>\n",
       "      <td>96.8</td>\n",
       "      <td>117.8</td>\n",
       "      <td>...</td>\n",
       "      <td>4.51</td>\n",
       "      <td>13.3</td>\n",
       "      <td>0.021</td>\n",
       "      <td>54</td>\n",
       "      <td>28</td>\n",
       "      <td>0.659</td>\n",
       "      <td>0.629</td>\n",
       "      <td>0.642</td>\n",
       "      <td>0.030</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>East</td>\n",
       "      <td>Central</td>\n",
       "      <td>82</td>\n",
       "      <td>112.3</td>\n",
       "      <td>106.9</td>\n",
       "      <td>5.4</td>\n",
       "      <td>95.6</td>\n",
       "      <td>116.2</td>\n",
       "      <td>...</td>\n",
       "      <td>4.57</td>\n",
       "      <td>12.9</td>\n",
       "      <td>0.004</td>\n",
       "      <td>51</td>\n",
       "      <td>31</td>\n",
       "      <td>0.622</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.678</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>New York</td>\n",
       "      <td>East</td>\n",
       "      <td>Atlantic</td>\n",
       "      <td>82</td>\n",
       "      <td>116.0</td>\n",
       "      <td>113.1</td>\n",
       "      <td>2.9</td>\n",
       "      <td>97.1</td>\n",
       "      <td>117.8</td>\n",
       "      <td>...</td>\n",
       "      <td>2.88</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.021</td>\n",
       "      <td>47</td>\n",
       "      <td>35</td>\n",
       "      <td>0.573</td>\n",
       "      <td>0.589</td>\n",
       "      <td>0.595</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>East</td>\n",
       "      <td>Atlantic</td>\n",
       "      <td>82</td>\n",
       "      <td>113.4</td>\n",
       "      <td>112.5</td>\n",
       "      <td>0.9</td>\n",
       "      <td>98.3</td>\n",
       "      <td>115.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>15.6</td>\n",
       "      <td>0.036</td>\n",
       "      <td>45</td>\n",
       "      <td>37</td>\n",
       "      <td>0.549</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.028</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Miami</td>\n",
       "      <td>East</td>\n",
       "      <td>Southeast</td>\n",
       "      <td>82</td>\n",
       "      <td>109.5</td>\n",
       "      <td>109.8</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>96.1</td>\n",
       "      <td>113.2</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.37</td>\n",
       "      <td>11.8</td>\n",
       "      <td>-0.070</td>\n",
       "      <td>44</td>\n",
       "      <td>38</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.047</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>East</td>\n",
       "      <td>Southeast</td>\n",
       "      <td>82</td>\n",
       "      <td>118.4</td>\n",
       "      <td>118.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>100.7</td>\n",
       "      <td>116.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.92</td>\n",
       "      <td>12.9</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.509</td>\n",
       "      <td>0.510</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>East</td>\n",
       "      <td>Atlantic</td>\n",
       "      <td>82</td>\n",
       "      <td>112.9</td>\n",
       "      <td>111.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>97.1</td>\n",
       "      <td>115.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.18</td>\n",
       "      <td>12.5</td>\n",
       "      <td>-0.119</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.548</td>\n",
       "      <td>0.549</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>East</td>\n",
       "      <td>Central</td>\n",
       "      <td>82</td>\n",
       "      <td>113.1</td>\n",
       "      <td>111.8</td>\n",
       "      <td>1.3</td>\n",
       "      <td>98.5</td>\n",
       "      <td>113.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.41</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>40</td>\n",
       "      <td>42</td>\n",
       "      <td>0.488</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.543</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Indiana</td>\n",
       "      <td>East</td>\n",
       "      <td>Central</td>\n",
       "      <td>82</td>\n",
       "      <td>116.3</td>\n",
       "      <td>119.5</td>\n",
       "      <td>-3.2</td>\n",
       "      <td>100.9</td>\n",
       "      <td>114.8</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.99</td>\n",
       "      <td>10.8</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>35</td>\n",
       "      <td>47</td>\n",
       "      <td>0.427</td>\n",
       "      <td>0.387</td>\n",
       "      <td>0.395</td>\n",
       "      <td>0.040</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Washington</td>\n",
       "      <td>East</td>\n",
       "      <td>Southeast</td>\n",
       "      <td>82</td>\n",
       "      <td>113.2</td>\n",
       "      <td>114.4</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>98.5</td>\n",
       "      <td>114.5</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>13.2</td>\n",
       "      <td>0.032</td>\n",
       "      <td>35</td>\n",
       "      <td>47</td>\n",
       "      <td>0.427</td>\n",
       "      <td>0.464</td>\n",
       "      <td>0.460</td>\n",
       "      <td>-0.037</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Orlando</td>\n",
       "      <td>East</td>\n",
       "      <td>Southeast</td>\n",
       "      <td>82</td>\n",
       "      <td>111.4</td>\n",
       "      <td>114.0</td>\n",
       "      <td>-2.6</td>\n",
       "      <td>99.2</td>\n",
       "      <td>111.7</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.59</td>\n",
       "      <td>12.1</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>34</td>\n",
       "      <td>48</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.414</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Charlotte</td>\n",
       "      <td>East</td>\n",
       "      <td>Southeast</td>\n",
       "      <td>82</td>\n",
       "      <td>111.0</td>\n",
       "      <td>117.2</td>\n",
       "      <td>-6.2</td>\n",
       "      <td>100.8</td>\n",
       "      <td>109.3</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.99</td>\n",
       "      <td>13.0</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>27</td>\n",
       "      <td>55</td>\n",
       "      <td>0.329</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.009</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Detroit</td>\n",
       "      <td>East</td>\n",
       "      <td>Central</td>\n",
       "      <td>82</td>\n",
       "      <td>110.3</td>\n",
       "      <td>118.5</td>\n",
       "      <td>-8.2</td>\n",
       "      <td>99.0</td>\n",
       "      <td>110.7</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.38</td>\n",
       "      <td>12.3</td>\n",
       "      <td>-0.040</td>\n",
       "      <td>17</td>\n",
       "      <td>65</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.230</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Denver</td>\n",
       "      <td>West</td>\n",
       "      <td>Northwest</td>\n",
       "      <td>82</td>\n",
       "      <td>115.8</td>\n",
       "      <td>112.5</td>\n",
       "      <td>3.3</td>\n",
       "      <td>98.1</td>\n",
       "      <td>117.6</td>\n",
       "      <td>...</td>\n",
       "      <td>2.84</td>\n",
       "      <td>14.3</td>\n",
       "      <td>0.058</td>\n",
       "      <td>53</td>\n",
       "      <td>29</td>\n",
       "      <td>0.646</td>\n",
       "      <td>0.594</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.052</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Memphis</td>\n",
       "      <td>West</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>82</td>\n",
       "      <td>116.9</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>101.0</td>\n",
       "      <td>115.1</td>\n",
       "      <td>...</td>\n",
       "      <td>3.31</td>\n",
       "      <td>14.7</td>\n",
       "      <td>0.007</td>\n",
       "      <td>51</td>\n",
       "      <td>31</td>\n",
       "      <td>0.622</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.628</td>\n",
       "      <td>0.020</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Sacramento</td>\n",
       "      <td>West</td>\n",
       "      <td>Pacific</td>\n",
       "      <td>82</td>\n",
       "      <td>120.8</td>\n",
       "      <td>118.1</td>\n",
       "      <td>2.7</td>\n",
       "      <td>100.3</td>\n",
       "      <td>119.5</td>\n",
       "      <td>...</td>\n",
       "      <td>2.11</td>\n",
       "      <td>13.5</td>\n",
       "      <td>0.006</td>\n",
       "      <td>48</td>\n",
       "      <td>34</td>\n",
       "      <td>0.585</td>\n",
       "      <td>0.577</td>\n",
       "      <td>0.589</td>\n",
       "      <td>0.008</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>West</td>\n",
       "      <td>Pacific</td>\n",
       "      <td>82</td>\n",
       "      <td>113.6</td>\n",
       "      <td>111.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>98.2</td>\n",
       "      <td>115.2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.44</td>\n",
       "      <td>15.2</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>45</td>\n",
       "      <td>37</td>\n",
       "      <td>0.549</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.566</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Golden State</td>\n",
       "      <td>West</td>\n",
       "      <td>Pacific</td>\n",
       "      <td>82</td>\n",
       "      <td>118.9</td>\n",
       "      <td>117.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>101.7</td>\n",
       "      <td>116.4</td>\n",
       "      <td>...</td>\n",
       "      <td>2.07</td>\n",
       "      <td>15.4</td>\n",
       "      <td>0.067</td>\n",
       "      <td>44</td>\n",
       "      <td>38</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.544</td>\n",
       "      <td>0.559</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>LA Clippers</td>\n",
       "      <td>West</td>\n",
       "      <td>Pacific</td>\n",
       "      <td>82</td>\n",
       "      <td>113.6</td>\n",
       "      <td>113.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>97.9</td>\n",
       "      <td>115.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.61</td>\n",
       "      <td>13.5</td>\n",
       "      <td>0.028</td>\n",
       "      <td>44</td>\n",
       "      <td>38</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.515</td>\n",
       "      <td>0.516</td>\n",
       "      <td>0.022</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>LA Lakers</td>\n",
       "      <td>West</td>\n",
       "      <td>Pacific</td>\n",
       "      <td>82</td>\n",
       "      <td>117.2</td>\n",
       "      <td>116.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>101.3</td>\n",
       "      <td>114.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.83</td>\n",
       "      <td>11.3</td>\n",
       "      <td>0.024</td>\n",
       "      <td>43</td>\n",
       "      <td>39</td>\n",
       "      <td>0.524</td>\n",
       "      <td>0.518</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.006</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>West</td>\n",
       "      <td>Northwest</td>\n",
       "      <td>82</td>\n",
       "      <td>115.8</td>\n",
       "      <td>115.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>113.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.32</td>\n",
       "      <td>11.6</td>\n",
       "      <td>0.020</td>\n",
       "      <td>42</td>\n",
       "      <td>40</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.012</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NaN</td>\n",
       "      <td>New Orleans</td>\n",
       "      <td>West</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>82</td>\n",
       "      <td>114.4</td>\n",
       "      <td>112.5</td>\n",
       "      <td>1.9</td>\n",
       "      <td>99.0</td>\n",
       "      <td>114.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.77</td>\n",
       "      <td>14.7</td>\n",
       "      <td>0.001</td>\n",
       "      <td>42</td>\n",
       "      <td>40</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.551</td>\n",
       "      <td>0.563</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Oklahoma City</td>\n",
       "      <td>West</td>\n",
       "      <td>Northwest</td>\n",
       "      <td>82</td>\n",
       "      <td>117.5</td>\n",
       "      <td>116.4</td>\n",
       "      <td>1.1</td>\n",
       "      <td>101.1</td>\n",
       "      <td>115.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.80</td>\n",
       "      <td>12.7</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>40</td>\n",
       "      <td>42</td>\n",
       "      <td>0.488</td>\n",
       "      <td>0.531</td>\n",
       "      <td>0.536</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>West</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>82</td>\n",
       "      <td>114.2</td>\n",
       "      <td>114.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>96.5</td>\n",
       "      <td>116.9</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>12.3</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>38</td>\n",
       "      <td>44</td>\n",
       "      <td>0.463</td>\n",
       "      <td>0.503</td>\n",
       "      <td>0.503</td>\n",
       "      <td>-0.040</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Utah</td>\n",
       "      <td>West</td>\n",
       "      <td>Northwest</td>\n",
       "      <td>82</td>\n",
       "      <td>117.1</td>\n",
       "      <td>118.1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>100.4</td>\n",
       "      <td>115.8</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.16</td>\n",
       "      <td>11.4</td>\n",
       "      <td>0.043</td>\n",
       "      <td>37</td>\n",
       "      <td>45</td>\n",
       "      <td>0.451</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.467</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Portland</td>\n",
       "      <td>West</td>\n",
       "      <td>Northwest</td>\n",
       "      <td>82</td>\n",
       "      <td>113.4</td>\n",
       "      <td>117.4</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>98.5</td>\n",
       "      <td>114.8</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.01</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>33</td>\n",
       "      <td>49</td>\n",
       "      <td>0.402</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.368</td>\n",
       "      <td>0.010</td>\n",
       "      <td>-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Houston</td>\n",
       "      <td>West</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>82</td>\n",
       "      <td>110.7</td>\n",
       "      <td>118.6</td>\n",
       "      <td>-7.9</td>\n",
       "      <td>99.0</td>\n",
       "      <td>111.4</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.24</td>\n",
       "      <td>12.6</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>22</td>\n",
       "      <td>60</td>\n",
       "      <td>0.268</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.003</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>West</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>82</td>\n",
       "      <td>113.0</td>\n",
       "      <td>123.1</td>\n",
       "      <td>-10.1</td>\n",
       "      <td>101.6</td>\n",
       "      <td>110.3</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.27</td>\n",
       "      <td>14.9</td>\n",
       "      <td>-0.059</td>\n",
       "      <td>22</td>\n",
       "      <td>60</td>\n",
       "      <td>0.268</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.012</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    RANK           TEAM  CONF   DIVISION  GP    PPG   oPPG  pDIFF   PACE  \\\n",
       "0    NaN      Milwaukee  East    Central  82  116.9  113.3    3.6  100.5   \n",
       "1    NaN         Boston  East   Atlantic  82  117.9  111.4    6.5   98.4   \n",
       "2    NaN   Philadelphia  East   Atlantic  82  115.2  110.9    4.3   96.8   \n",
       "3    NaN      Cleveland  East    Central  82  112.3  106.9    5.4   95.6   \n",
       "4    NaN       New York  East   Atlantic  82  116.0  113.1    2.9   97.1   \n",
       "5    NaN       Brooklyn  East   Atlantic  82  113.4  112.5    0.9   98.3   \n",
       "6    NaN          Miami  East  Southeast  82  109.5  109.8   -0.3   96.1   \n",
       "7    NaN        Atlanta  East  Southeast  82  118.4  118.1    0.3  100.7   \n",
       "8    NaN        Toronto  East   Atlantic  82  112.9  111.4    1.5   97.1   \n",
       "9    NaN        Chicago  East    Central  82  113.1  111.8    1.3   98.5   \n",
       "10   NaN        Indiana  East    Central  82  116.3  119.5   -3.2  100.9   \n",
       "11   NaN     Washington  East  Southeast  82  113.2  114.4   -1.2   98.5   \n",
       "12   NaN        Orlando  East  Southeast  82  111.4  114.0   -2.6   99.2   \n",
       "13   NaN      Charlotte  East  Southeast  82  111.0  117.2   -6.2  100.8   \n",
       "14   NaN        Detroit  East    Central  82  110.3  118.5   -8.2   99.0   \n",
       "15   NaN         Denver  West  Northwest  82  115.8  112.5    3.3   98.1   \n",
       "16   NaN        Memphis  West  Southwest  82  116.9  113.0    3.9  101.0   \n",
       "17   NaN     Sacramento  West    Pacific  82  120.8  118.1    2.7  100.3   \n",
       "18   NaN        Phoenix  West    Pacific  82  113.6  111.6    2.0   98.2   \n",
       "19   NaN   Golden State  West    Pacific  82  118.9  117.1    1.8  101.7   \n",
       "20   NaN    LA Clippers  West    Pacific  82  113.6  113.1    0.5   97.9   \n",
       "21   NaN      LA Lakers  West    Pacific  82  117.2  116.6    0.6  101.3   \n",
       "22   NaN      Minnesota  West  Northwest  82  115.8  115.8    0.0  101.0   \n",
       "23   NaN    New Orleans  West  Southwest  82  114.4  112.5    1.9   99.0   \n",
       "24   NaN  Oklahoma City  West  Northwest  82  117.5  116.4    1.1  101.1   \n",
       "25   NaN         Dallas  West  Southwest  82  114.2  114.1    0.1   96.5   \n",
       "26   NaN           Utah  West  Northwest  82  117.1  118.1   -1.0  100.4   \n",
       "27   NaN       Portland  West  Northwest  82  113.4  117.4   -4.0   98.5   \n",
       "28   NaN        Houston  West  Southwest  82  110.7  118.6   -7.9   99.0   \n",
       "29   NaN    San Antonio  West  Southwest  82  113.0  123.1  -10.1  101.6   \n",
       "\n",
       "     oEFF  ...   SAR  CONS    A4F   W   L   WIN%  eWIN%  pWIN%    ACH  STRK  \n",
       "0   115.5  ...  3.16  15.0  0.086  58  24  0.707  0.595  0.619  0.112    -2  \n",
       "1   118.1  ...  5.76  14.3  0.063  57  25  0.695  0.677  0.714  0.018     3  \n",
       "2   117.8  ...  4.51  13.3  0.021  54  28  0.659  0.629  0.642  0.030     2  \n",
       "3   116.2  ...  4.57  12.9  0.004  51  31  0.622  0.667  0.678 -0.045    -1  \n",
       "4   117.8  ...  2.88  13.0  0.021  47  35  0.573  0.589  0.595 -0.016    -2  \n",
       "5   115.0  ...  0.75  15.6  0.036  45  37  0.549  0.521  0.530  0.028    -1  \n",
       "6   113.2  ... -0.37  11.8 -0.070  44  38  0.537  0.490  0.490  0.047     1  \n",
       "7   116.7  ...  0.92  12.9 -0.026  41  41  0.500  0.509  0.510 -0.009    -2  \n",
       "8   115.5  ...  1.18  12.5 -0.119  41  41  0.500  0.548  0.549 -0.048     1  \n",
       "9   113.5  ...  1.41  15.0 -0.013  40  42  0.488  0.534  0.543 -0.046     2  \n",
       "10  114.8  ... -2.99  10.8 -0.027  35  47  0.427  0.387  0.395  0.040     1  \n",
       "11  114.5  ... -1.00  13.2  0.032  35  47  0.427  0.464  0.460 -0.037    -1  \n",
       "12  111.7  ... -1.59  12.1 -0.015  34  48  0.415  0.415  0.414  0.000    -4  \n",
       "13  109.3  ... -4.99  13.0 -0.044  27  55  0.329  0.320  0.296  0.009     1  \n",
       "14  110.7  ... -7.38  12.3 -0.040  17  65  0.207  0.250  0.230 -0.043    -1  \n",
       "15  117.6  ...  2.84  14.3  0.058  53  29  0.646  0.594  0.609  0.052     1  \n",
       "16  115.1  ...  3.31  14.7  0.007  51  31  0.622  0.602  0.628  0.020    -1  \n",
       "17  119.5  ...  2.11  13.5  0.006  48  34  0.585  0.577  0.589  0.008    -3  \n",
       "18  115.2  ...  2.44  15.2 -0.001  45  37  0.549  0.555  0.566 -0.006    -2  \n",
       "19  116.4  ...  2.07  15.4  0.067  44  38  0.537  0.544  0.559 -0.007     3  \n",
       "20  115.1  ...  0.61  13.5  0.028  44  38  0.537  0.515  0.516  0.022     3  \n",
       "21  114.5  ...  0.83  11.3  0.024  43  39  0.524  0.518  0.520  0.006     2  \n",
       "22  113.8  ...  0.32  11.6  0.020  42  40  0.512  0.500  0.500  0.012     3  \n",
       "23  114.5  ...  1.77  14.7  0.001  42  40  0.512  0.551  0.563 -0.039    -1  \n",
       "24  115.4  ...  0.80  12.7 -0.068  40  42  0.488  0.531  0.536 -0.043     2  \n",
       "25  116.9  ... -0.25  12.3 -0.002  38  44  0.463  0.503  0.503 -0.040    -2  \n",
       "26  115.8  ... -1.16  11.4  0.043  37  45  0.451  0.465  0.467 -0.014    -1  \n",
       "27  114.8  ... -4.01  15.0 -0.015  33  49  0.402  0.392  0.368  0.010    -4  \n",
       "28  111.4  ... -7.24  12.6 -0.026  22  60  0.268  0.265  0.240  0.003     3  \n",
       "29  110.3  ... -9.27  14.9 -0.059  22  60  0.268  0.256  0.167  0.012     1  \n",
       "\n",
       "[30 rows x 24 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team = pd.read_csv('./data/2023_teams.csv')\n",
    "team"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50ea713-3073-400c-a881-eb6d969dfcfe",
   "metadata": {},
   "source": [
    "Legend: <br><br>\n",
    "RANK: Determined by Win-Loss Record (1 = most wins, 30 = least wins) <br><br>\n",
    "TEAM: City the team plays in <br><br>\n",
    "CONFERENCE: Conference the team plays in (either East or West) <br><br>\n",
    "DIVISION: Division team plays in <br><br>\n",
    "GP: Games played <br><br>\n",
    "PPG: Points Scored Per Game <br><br>\n",
    "oPPG: Points Allowed Per Game <br><br>\n",
    "pDIFF: Points Differential = [(Total Points Scored) – (Total Points Allowed)]/ (Games Played) <br><br>\n",
    "PACE: Pace, an estimate of Possessions Per 48 Minutes <br><br>\n",
    "oEFF: Offensive Efficiency, points scored per 100 possessions <br><br>\n",
    "dEFF: Defensive Efficiency, points allowed per 100 possessions <br><br>\n",
    "eDIFF: Efficiency Differential = [(Total Offensive Efficiency) – (Total Defensive Efficiency)]/ (Games Played) <br><br>\n",
    "SOS: Strength of the Schedule, Opponent efficiency differential average for all games played so far (venue of the games also taken into account) is used as an indicator of the strength of the schedule. The higher the SoS rating, the tougher the schedule; where zero is average <br><br>\n",
    "rSOS: Remaining Strength of the Schedule, Opponent efficiency differential average for the remaining games (venue of the games also taken into account) is used as an indicator of the strength of the schedule. The higher the rSOS rating, the tougher the remaining schedule; where zero is average <br><br>\n",
    "SAR: Schedule Adjusted Rating, an evaluation of teams based on efficiency differential and strength of schedule <br><br>\n",
    "CONS: Consistency Rating, consistency based on game-by-game efficiency differential variation. The higher the team has consistency rating, the more unpredictable it is <br><br>\n",
    "a4F: Adjusted Four Factors, calculated by applying weights to the differentials of offensive and defensive four factors. A4F explains the specified proportion of variability in wins <br><br>\n",
    "W: Wins: Total number of games won <br><br>\n",
    "L: Losses: Total number of games lost <br><br>\n",
    "W%: Winning percentage <br><br>\n",
    "eWIN%: Correlated Gaussian Expected Winning Percentage, indicates the ideal winning percentage based on offensive and defensive performance <br><br>\n",
    "pWIN%: Projected Winning Percentage, each point differential translates to 2.7 wins over the course of the season <br><br>\n",
    "ACH: Achievement Level In Terms of Wins, this metric is based on the differential between actual and expected winning percentages. Positive figures indicate overachievement while negative figures indicate the team should have won more games. <br><br>\n",
    "STRK: Current Streak, winning or losing streak for the season <br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402f96b4-fa74-4e85-88f7-9fb1ad28ceca",
   "metadata": {},
   "source": [
    "For our outcome variable, winning, we will use wins (W) as they are a whole number and guaranteed to be between 0-82. Given that W + L = 82, we can drop our L (loss) column. For this same reason, we will drop Games Played (GP) as all teams played 82 games, and will drop STRK bc it only shows the current streak, not all streaks for the entire season and therefore likely lacks much predictive value. RANK is also based on Wins, so this will be dropped.\n",
    "\n",
    "As for other columns to drop, we will remove Conference, Division, and Team, as they are categorical variables that are not advanced statistics, so they serve no purpose in our analysis. \n",
    "\n",
    "We will even remove some advanced statistics as well. The rSOS (remaining Strength of Schedule) metric is based on the assumption there are games left in the season, but since the season is completed, we can use the normal SOS metric. We will drop PPG, oPPG in favor of pDiff, as pDiff is the difference of the former two statistics. The same logic will apply to dropping oEFF and dEFF in favor of eDIFF. a4F is a linear combination of offensive/defensive metrics, which we have already accounted for, so we will drop this column. SAR is a combination of eDIFF and SOS, which we are already using. Finally, eWIN%, pWIN%, and ACH are not really advanced statistics that have much interested as they are based on statistics we are already using. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd89e2a-cff4-425f-a00d-4af354216ba2",
   "metadata": {},
   "source": [
    "This leaves us with a final set of features of: pDIFF, Pace, eDIFF, SOS, and CONS. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "176fdc76-62a3-4feb-ab9e-6e8f82a4dcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = team[['pDIFF', 'PACE', 'eDIFF', 'SOS', 'CONS']]\n",
    "outcome = team['W']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dce219c-9b9d-4484-a048-1bc3aa31f82b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eae4756-f2d6-4031-9e45-83db26c6b1fe",
   "metadata": {},
   "source": [
    "#### Training the Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c34deef-12ab-42f5-ad21-689f24ec23ce",
   "metadata": {},
   "source": [
    "I chose to use Random Forests for this problem because it is a powerful and versatile method that can capture complex relationships between features and target variables. Random Forests are an ensemble learning method that constructs multiple decision trees and combines their predictions to improve the overall accuracy and control overfitting.\n",
    "\n",
    "Random Forests already implement bagging by constructing multiple decision trees, but in order to prevent even more overfitting, we will put a maximum depth on our trees. The default depth for regression is considered to be 1/3 of the number of features, so we will implement this accordingly. Also, we will use the convention of sqrt(number of features) for the maximum number of features to use at each split of the tree, again another popular convention. \n",
    "\n",
    "For a train-test split, I will use the convention of an 70-30 split. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9eac84cb-f9c3-4c47-90a8-fdcb3f2fb49f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Root Mean Squared Error: 5.33\n",
      "Train R²: 0.73\n"
     ]
    }
   ],
   "source": [
    "# Preparation\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, outcome, test_size=0.3, random_state=42)\n",
    "\n",
    "# Training\n",
    "rf_model = RandomForestRegressor(max_depth = int(len(features.columns)/3), max_features = int(np.sqrt(len(features.columns))), random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Training Predictions\n",
    "y_train_pred = rf_model.predict(X_train)\n",
    "\n",
    "# Training Evaluation\n",
    "train_rmse = mean_squared_error(y_train, y_train_pred)**0.5\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "\n",
    "print(\"Train Root Mean Squared Error:\", round(train_rmse, 2))\n",
    "print(\"Train R\\u00B2:\", round(train_r2, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76472741-00e3-4826-b5f0-6d322a8d9dd7",
   "metadata": {},
   "source": [
    "This RMSE is not bad, and our $R^2$ is decent as well. Let's see if we can replicate this performance on our test data:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8c43c8-30fd-492a-891e-9ae09717094d",
   "metadata": {},
   "source": [
    "#### Test Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "95b1813c-75fe-445f-88a0-5b919aa1fa9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Root Mean Squared Error: 4.66\n",
      "Test R²: 0.7\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = rf_model.predict(X_test)\n",
    "\n",
    "test_rmse = mean_squared_error(y_test, y_test_pred)**0.5\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"Test Root Mean Squared Error:\", round(test_rmse, 2))\n",
    "print(\"Test R\\u00B2:\", round(test_r2, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0895a4-0269-4489-a808-13702f8d8b76",
   "metadata": {},
   "source": [
    "Interestingly, our RMSE is lower, but our $R^2$ is also lower. This is a relatively small change, so this could very well be variation within the test vs. training dataset. This gives us some confidence that our model does not have an overfitting problem, and could generalize well to different data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cdc7af2-9394-47ca-9f0c-da8adcd7bcef",
   "metadata": {},
   "source": [
    "We made a decent predictor using a nonparametric ensemble model, meaning we made no assumptions about the distribution of our data, and used a mutlitude of models (in this case, decision trees), to ensure we were not overly susceptible to chance variation.\n",
    "\n",
    "Can we create a stronger model if we make assumptions about our data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718326a0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Bayesian Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a258a3c",
   "metadata": {},
   "source": [
    "#### The General Linear Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01394238",
   "metadata": {},
   "source": [
    "I will use a Bayesian linear regression model as our Bayesian Generalized Linear Model (GLM). It is a very interpretable method for predicting the success of NBA teams based on the selected features. Linear regression models assume a linear relationship between the predictors and the target variable, which can help us understand the individual contributions of each feature to the winning percentage of the teams.\n",
    "\n",
    "What is the difference between using a GLM vs. standard linear regression? In a GLM, we treat our predictors as random variables, not as constants. So, random variables have distributions. We use a prior distribution that takes into account what we know about the given predictors, and as our data is processed, we use Bayes' rule to update the distributions in the form of a posterior distribution. If we knew a lot about our data, we would want to use a strong prior distribution (i.e., one with lower variance) and therefore not let the data influence the posterior distribution as much. However, since we are starting off without much information, we will use a weak prior of a normal distribution with mean 0 and variance 100, letting our data greatly influence the posterior distributions.\n",
    "\n",
    "We also have a link and likelihood function. The link function tells us how our linear predictor maps to the expected value of the predictor variables. Since we don't know much about our data, and are using a linear regression, we will assume our data takes on a Normal Distribution. Therefore, we use the identity link function, which assumes our outcome variable can be a linear combination of our predictor variables. The likelihood function tells us the probability of having seen the given data, under assumptions about our parameters. Since we assume our parameters are normally distributed, we use a Gaussian likelihood. \n",
    "\n",
    "The Bayesian linear regression model assumes the following form:\n",
    "\n",
    "`W = β0 + β1 * pDIFF + β2 * PACE + β3 * eDIFF + β4 * SOS + β5 * CONS + ε`\n",
    "\n",
    "where βi represents the coefficients for each feature, and ε is the error term.\n",
    "\n",
    "As mentioned, the Bayesian GLM linear regression makes parametric assumptions about our data. They are:\n",
    "\n",
    "1. Linearity: The relationship between the predictors and the target variable is assumed to be linear. This may not always hold true in practice, but it serves as a starting point for understanding the relationships between the features and the winning percentage.\n",
    "2. Independence: The observations are assumed to be independent of each other. In the context of the NBA, this might not be completely accurate, as team performance can be influenced by various external factors such as injuries or changes in coaching staff. However, this assumption simplifies the model and allows us to focus on the relationships between the features and the target variable.\n",
    "3. Homoscedasticity: The model assumes that the variance of the error term is constant across all levels of the predictors. This might not always be true in practice, as certain predictors may exhibit different variances at different levels.\n",
    "\n",
    "Note that our assumptions here likely do not hold true, so we must be careful regarding our interpretation of the model. However, let us proceed with caution to see what our model tells us. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78b178b-4029-4870-a0d2-09417a25f6f1",
   "metadata": {},
   "source": [
    "#### Model Specifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "55e60c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features and outcome to have mean = 0, sd = 1\n",
    "standardized_features = (features - features.mean())/features.std()\n",
    "standardized_outcome = (outcome - outcome.mean())/outcome.std()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(standardized_features, standardized_outcome, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4c1954",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_243/482350756.py:15: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(2000, tune=1000, cores=2)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (2 chains in 2 jobs)\n",
      "NUTS: [sigma, betas, beta_0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='5320' class='' max='6000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      88.67% [5320/6000 03:26&lt;00:26 Sampling 2 chains, 1,877 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model specification\n",
    "with pm.Model() as bayesian_model:\n",
    "    # Priors\n",
    "    beta_0 = pm.Normal('beta_0', mu=0, sd=100)\n",
    "    betas = pm.Normal('betas', mu=0, sd=100, shape=X_train.shape[1])\n",
    "\n",
    "    # Linear regression model\n",
    "    mu = beta_0 + tt.dot(X_train, betas)\n",
    "\n",
    "    # Likelihood\n",
    "    sigma = pm.HalfNormal('sigma', sd=100)\n",
    "    y_obs = pm.Normal('y_obs', mu=mu, sd=sigma, observed=y_train)\n",
    "\n",
    "    # Sample from the posterior\n",
    "    trace = pm.sample(2000, tune=1000, cores=2)\n",
    "\n",
    "# summary\n",
    "pm.summary(trace).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ceddd7-2de9-4070-a0e3-2615210d7b62",
   "metadata": {},
   "source": [
    "#### Training Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5001a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model evaluation\n",
    "with bayesian_model:\n",
    "    # Posterior predictive checks (PPC) on test data\n",
    "    ppc = pm.sample_posterior_predictive(trace, var_names=['beta_0', 'betas', 'sigma'], samples=500)\n",
    "    y_train_pred = ppc['beta_0'].mean(axis=0) + np.dot(X_train, ppc['betas'].mean(axis=0))\n",
    "\n",
    "    # Peformance metrics \n",
    "    rmse = mean_squared_error(y_train, y_train_pred)\n",
    "    print(f'Train Root Mean Squared Error: {mse:.2f}')\n",
    "\n",
    "    r2 = r2_score(y_train, y_train_pred)\n",
    "    print(f'Train R\\u00B2: {r2:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97dbb43a-eb9b-423f-8342-ba65650cec5d",
   "metadata": {},
   "source": [
    "#### Test Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34a0bb5-aa03-40ab-b8fb-ec21d730f005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model evaluation\n",
    "with bayesian_model:\n",
    "    # Posterior predictive checks (PPC) on test data\n",
    "    ppc = pm.sample_posterior_predictive(trace, var_names=['beta_0', 'betas', 'sigma'], samples=500)\n",
    "    y_test_pred = ppc['beta_0'].mean(axis=0) + np.dot(X_test, ppc['betas'].mean(axis=0))\n",
    "\n",
    "    # Peformance metrics \n",
    "    rmse = mean_squared_error(y_test, y_test_pred)\n",
    "    print(f'Test Root Mean Squared Error: {mse:.2f}')\n",
    "\n",
    "    r2 = r2_score(y_test, y_test_pred)\n",
    "    print(f'Test R\\u00B2: {r2:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc68dd3b",
   "metadata": {},
   "source": [
    "Based on the mean squared error (MSE) of 0.07 and the R-squared score of 0.92, the Bayesian GLM appears to perform well on the test data. The low MSE suggests that the model's predictions are close to the true values, and the high R-squared score indicates that the model explains a large proportion of the variance in the dependent variable. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0d9f03",
   "metadata": {},
   "source": [
    "Since the model only considers a limited set of features, some that could have a significant impact on team success are excluded, such as team chemistry, coaching, and injuries. Additionally, the model assumes a linear relationship between the features and the target, which may not always be the case. Finally, the model was trained on a single season of data, so its ability to generalize to other seasons is uncertain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fd41b2",
   "metadata": {},
   "source": [
    "The uncertainty in the results is relatively low, which is indicated by the narrow credible intervals (hdi_3% to hdi_97%) for the parameters and the relatively small standard deviations for most of the variables. However, there is a high uncertainty in the estimates for betas[3], betas[4], and betas[5], as indicated by their wide credible intervals and high standard deviations. This high uncertainty may be due to the relatively small dataset size, the noise in the data, or the complexity of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ffc406",
   "metadata": {},
   "source": [
    "## Model Comparison, Limitations on Generalizability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330a0c2e",
   "metadata": {},
   "source": [
    "Based on the results, decision-makers in the NBA can use the models to inform their decisions related to team composition and strategy, but they should also consider the limitations and uncertainties associated with the models. The Bayesian model provides uncertainty estimates, which can be useful for decision-making, while the frequentist model has slightly better performance metrics. The Random Forest model performed the best in predicting team success, but the perfect fit may indicate overfitting or data leakage, and further investigation is needed to increase confidence in its applicability to future datasets.\n",
    "\n",
    "A limitation of the models is that they only consider a limited set of features and do not capture factors such as team chemistry, coaching, and injuries. Future work could incorporate additional features and explore different modeling techniques to improve the models' performance and generalizability.\n",
    "\n",
    "The results also show that the models' predictions are consistent with the actual teams that made it to the playoffs, suggesting their real-world applicability. However, decision-makers should still exercise caution when using the models to inform their decisions and consider additional factors that may impact team success.\n",
    "\n",
    "In summary, the models provide a useful tool for predicting team success based on selected features, but decision-makers should consider their limitations and uncertainties. Future work could explore additional features and modeling techniques to improve performance and generalizability.\n",
    "\n",
    "A call to action based on the results is to encourage decision-makers in the NBA to use these models as one of many tools to inform their decisions related to team composition and strategy. The models provide valuable insights into the relationships between features and team success and can help decision-makers make more informed decisions. However, decision-makers should also consider other factors that may impact team success, such as team chemistry, coaching, and injuries, and exercise caution when using the models to inform their decisions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
